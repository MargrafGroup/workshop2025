{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Notebook\n",
    "\n",
    "This notebook provides some rough markdown comment guidelines for you to program your own invariant/equivariant NN.\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import all the relevant packages.<br>\n",
    "Just come back and add what's missing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ase.io import read\n",
    "from ase.neighborlist import neighbor_list\n",
    "# from torch_scatter import scatter_add,scatter_sum\n",
    "from typing import List \n",
    "from e3nn import o3\n",
    "from e3nn.nn import Activation, Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):\n",
    "    if dim < 0:\n",
    "        dim = other.dim() + dim\n",
    "    if src.dim() == 1:\n",
    "        for _ in range(0, dim):\n",
    "            src = src.unsqueeze(0)\n",
    "    for _ in range(src.dim(), other.dim()):\n",
    "        src = src.unsqueeze(-1)\n",
    "    src = src.expand(other.size())\n",
    "    return src\n",
    "\n",
    "def scatter_sum(src: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                dim: int = -1,\n",
    "                out: Optional[torch.Tensor] = None,\n",
    "                dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    index = broadcast(index, src, dim)\n",
    "    if out is None:\n",
    "        size = list(src.size())\n",
    "        if dim_size is not None:\n",
    "            size[dim] = dim_size\n",
    "        elif index.numel() == 0:\n",
    "            size[dim] = 0\n",
    "        else:\n",
    "            size[dim] = int(index.max()) + 1\n",
    "        out = torch.zeros(size, dtype=src.dtype, device=src.device)\n",
    "        return out.scatter_add_(dim, index, src)\n",
    "    else:\n",
    "        return out.scatter_add_(dim, index, src)\n",
    "\n",
    "\n",
    "def scatter_add(src: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                dim: int = -1,\n",
    "                out: Optional[torch.Tensor] = None,\n",
    "                dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    return scatter_sum(src, index, dim, out, dim_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Molecular Graph Representation**\n",
    "\n",
    "\n",
    "Let's begin by defining an object containing the relevant graph information, derived from an ASE atoms object.\n",
    "\n",
    "We define a lightweight wrapper class that extracts geometric and chemical information from an ASE atoms object.\n",
    "<br> <br>\n",
    "\n",
    "<details>\n",
    "<summary> <strong> Hint </strong> (click me) </summary>\n",
    "\n",
    "Define some `__init__`, taking the `ase.atoms`-object, and a function to build a neighbour list.\n",
    "- Stores atomic positions and element types\n",
    "- Builds a neighbor list using ASE (with periodicity and cutoff)\n",
    "- Computes normalized direction vectors for atom pairs\n",
    "- Encodes element types as consecutive indices (not atomic numbers)\n",
    "</details>\n",
    "\n",
    "<br> \n",
    "\n",
    "<details>\n",
    "<summary> <strong> Neighbor list hint </strong> (click me) </summary>\n",
    "You can use ase neighbor list as this\n",
    "```\n",
    "from ase.neighborlist import neighbor_list\n",
    "idx_i, idx_j, d_ij, r_ij, S = neighbor_list(\"ijdDS\",at,cutoff=cutoff,self_interaction=False)\n",
    "```\n",
    "- Encodes element types as consecutive indices (not atomic numbers)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchAtoms():\n",
    "    def __init__(self,aseAtoms):\n",
    "        '''\n",
    "        Simple class containing molecular graph information based on an atoms object\n",
    "        '''\n",
    "        self.ase_mol = aseAtoms.copy()\n",
    "        self.xyz = torch.tensor(aseAtoms.get_positions())\n",
    "        self._build_neighbor_list()\n",
    "        self.elements = list(set(self.ase_mol.symbols))\n",
    "        self.n_elements = len(self.elements)\n",
    "        self.element_labels = torch.tensor([self.elements.index(sym) for sym in self.ase_mol.symbols]) # Elements are labeled consecutively not by atomic number (to match the index of the embedding)\n",
    "        self.n_atoms = len(aseAtoms)\n",
    "        \n",
    "    def _build_neighbor_list(self, cutoff=3.0):\n",
    "        at = self.ase_mol.copy()\n",
    "        at.center(vacuum=10)\n",
    "        idx_i, idx_j, d_ij, r_ij, S = neighbor_list(\"ijdDS\",at,cutoff=cutoff,self_interaction=False)\n",
    "        self.idx_i = torch.from_numpy(idx_i)\n",
    "        self.idx_j = torch.from_numpy(idx_j)\n",
    "        self.d_ij  = torch.from_numpy(d_ij).type(torch.FloatTensor)\n",
    "        self.r_ij  = torch.from_numpy(r_ij).type(torch.FloatTensor)\n",
    "        self.dir_ij = F.normalize(self.r_ij,p=2,dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-batching multiple molecular systems**\n",
    "\n",
    "For later usage, let's also already predefine a batched version of our `TorchAtoms`, where we concanate relevant tensors.\n",
    "\n",
    "Define a container that merges several `TorchAtoms` objects into a single batched structure.\n",
    "\n",
    "Another option is to use dataloader from `torch`, however for our simple case it is not fully needed\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary><strong> Hint </strong></summary>\n",
    "\n",
    "Each molecule has its own local atom indexing. To combine them into one large graph, indices must be shifted so they don’t overlap.\n",
    "    \n",
    "- Atom indices are adjusted via per-molecule offsets.\n",
    "- Neighbor and feature tensors are concatenated across molecules.\n",
    "- Each atom is tagged with a `mol_id` for later aggregation per system.\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedTorchAtoms():\n",
    "    def __init__(self, \n",
    "                 mol_list: List[TorchAtoms]):\n",
    "        offsets = []\n",
    "        cum = 0\n",
    "        for mol in mol_list:\n",
    "            offsets.append(cum)\n",
    "            cum += mol.n_atoms\n",
    "        self.n_mols = len(mol_list)\n",
    "        self.idx_i = torch.cat([m.idx_i + off for m, off in zip(mol_list, offsets)])\n",
    "        self.idx_j = torch.cat([m.idx_j + off for m, off in zip(mol_list, offsets)])\n",
    "        self.d_ij  = torch.cat([m.d_ij  for m in mol_list])\n",
    "        self.r_ij  = torch.cat([m.r_ij  for m in mol_list])\n",
    "        self.dir_ij = torch.cat([m.dir_ij for m in mol_list])\n",
    "        self.element_labels = torch.cat([m.element_labels for m in mol_list])\n",
    "        self.n_elements = torch.unique(self.element_labels).numel() \n",
    "        mol_ids = [ #This generates indexes of which atom belong to which system\n",
    "            torch.full((m.n_atoms,), idx, dtype=torch.long) \n",
    "            for idx, m in enumerate(mol_list)\n",
    "        ]\n",
    "        self.mol_id = torch.cat(mol_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and preprocess data**\n",
    "\n",
    "And load and prep objects of classes. Here we are providing data of water clusters calculated with FHI-aims on PBE0 level.\n",
    "\n",
    "We read a set of molecular structures (here: water clusters) and convert them into graph-based representations.\n",
    "\n",
    "<details>\n",
    "<summary><strong> Hint</strong></summary>\n",
    "\n",
    "This ASE syntax selects the first 10 configurations from a trajectory-style `.xyz` file.\n",
    "    \n",
    "- The `.xyz` file contains multiple frames; only the first 10 are read.\n",
    "- Each structure is wrapped as a `TorchAtoms` object.\n",
    "- A batched container combines all systems for model input.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Extract graph features**\n",
    "\n",
    "Then, retrieve atomic types, pairwise distances, directions, and neighbor indices from the batched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = read(\"waterAims.xyz@:10\",format=\"extxyz\")\n",
    "torch_mols = [TorchAtoms(mol) for mol in mols]\n",
    "batched_mols = BatchedTorchAtoms(torch_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_types = batched_mols.element_labels\n",
    "r_ij   = batched_mols.r_ij\n",
    "d_ij   = batched_mols.d_ij\n",
    "dir_ij = batched_mols.dir_ij\n",
    "idx_i  = batched_mols.idx_i\n",
    "idx_j  = batched_mols.idx_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ase.atoms obejct has following info and arrays. The important bits will be `dft_dipole` and `dft_hirshfeld`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dft_energy', 'dft_dipole']\n",
      "['numbers', 'positions', 'dft_forces', 'dft_hirshfeld']\n"
     ]
    }
   ],
   "source": [
    "print([k for k in mols[0].info])\n",
    "print([k for k in mols[0].arrays])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as we will do a one-batch training, the code will be the same, so feel free to use `batched_mols` or `[torch_mols[0]]` in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariant NN - SchNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atom-type embeddings**\n",
    "\n",
    "The first step towards building the atomic representations is to match each element to a vector of dimension `n_features` via a so called embedding (basically just an optimizable look-up table).\n",
    "\n",
    "Now, map discrete atomic species to continuous feature vectors using a learnable embedding layer.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong> Hint</strong></summary>\n",
    "\n",
    "An `nn.Embedding` turns integer-labeled types into dense vectors that can be optimized during training.  \n",
    "This is analogous to word embeddings in NLP, but here used for element types.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0109,  0.4197, -0.1325,  ...,  0.5523, -0.9241, -1.6046],\n",
      "        [-1.4363,  1.1540,  0.8700,  ..., -0.6151,  0.4054,  0.2882],\n",
      "        [-1.4363,  1.1540,  0.8700,  ..., -0.6151,  0.4054,  0.2882],\n",
      "        ...,\n",
      "        [-0.0109,  0.4197, -0.1325,  ...,  0.5523, -0.9241, -1.6046],\n",
      "        [-1.4363,  1.1540,  0.8700,  ..., -0.6151,  0.4054,  0.2882],\n",
      "        [-1.4363,  1.1540,  0.8700,  ..., -0.6151,  0.4054,  0.2882]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([240, 16])\n"
     ]
    }
   ],
   "source": [
    "n_elements = batched_mols.n_elements\n",
    "species_types = batched_mols.element_labels\n",
    "feature_dimension = 16\n",
    "element_embedding = nn.Embedding(n_elements, feature_dimension)\n",
    "node_embeddings = element_embedding(species_types)\n",
    "print(node_embeddings)\n",
    "print(node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edge features via radial basis functions**\n",
    "\n",
    "Next, we do the same thing with the edges of our graph (i.e. interatomic distances). Here we use some kind of radial basis functions (e.g. evenly spaced Gaussians).\n",
    "\n",
    "Code a class in order to project pairwise distances onto a fixed set of radial basis functions (RBFs), implemented as Gaussians.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong> Hint</strong></summary>\n",
    "\n",
    "Distances are continuous values. To represent them as input features, we expand them in a smooth basis (here: Gaussians)  \n",
    "centered along the range of expected distances. This helps the model capture distance-dependent interactions.\n",
    "Define a `__init__`-function for the class being a child of `nn.Modul`, and provide a `forward` method.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRBF(nn.Module):\n",
    "    def __init__(self, n_rbf, cutoff, start=0.0):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, cutoff, n_rbf)\n",
    "        width  = torch.abs(offset[1] - offset[0])\n",
    "        self.n_rbf = n_rbf\n",
    "        self.register_buffer(\"offset\", offset)\n",
    "        self.register_buffer(\"widths\", torch.full_like(offset, width))\n",
    "\n",
    "    def forward(self, d_ij):\n",
    "        return torch.exp(-((d_ij.unsqueeze(-1) - self.offset) ** 2) / self.widths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode edge distances**\n",
    "\n",
    "Apply the newly coded RBF expansion to pairwise distances to obtain edge features.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "\n",
    "Each edge gets a feature vector of length `n_rbf`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1558])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ij = batched_mols.d_ij\n",
    "d_ij.shape\n",
    "# d_ij = torch_mols[0].d_ij\n",
    "# d_ij.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1558, 10])\n",
      "tensor([[2.1320e-10, 3.5522e-08, 3.0386e-06,  ..., 6.3189e-01, 9.9001e-01,\n",
      "         7.9637e-01],\n",
      "        [6.0783e-02, 3.0076e-01, 7.6406e-01,  ..., 3.6706e-03, 1.7079e-04,\n",
      "         4.0801e-06],\n",
      "        [6.0807e-02, 3.0084e-01, 7.6416e-01,  ..., 3.6685e-03, 1.7067e-04,\n",
      "         4.0766e-06],\n",
      "        ...,\n",
      "        [2.8709e-05, 8.6100e-04, 1.3258e-02,  ..., 5.2095e-01, 1.4692e-01,\n",
      "         2.1273e-02],\n",
      "        [2.4658e-12, 6.9155e-10, 9.9578e-08,  ..., 2.7984e-01, 7.3803e-01,\n",
      "         9.9931e-01],\n",
      "        [8.1910e-04, 1.2749e-02, 1.0189e-01,  ..., 1.5077e-01, 2.2068e-02,\n",
      "         1.6584e-03]])\n"
     ]
    }
   ],
   "source": [
    "n_rbf = 10\n",
    "cutoff = 3.0\n",
    "RBF = SimpleRBF(n_rbf,cutoff)\n",
    "edge_embeddings = RBF(d_ij)\n",
    "\n",
    "print(edge_embeddings.shape)\n",
    "print(edge_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invariant Convolution**\n",
    "\n",
    "Finally, we need to define a module that allows us to couple the representations of the atoms (nodes) via the edges. To this end we can define a simple invariant convolution, based on the continuous filter convolution in SchNet. This works by projecting both edge and node embeddings to a common latent space (of dimension `filter_dimension`) and then computing a weighted sum over the neighboring atoms j as the message to atom i.\n",
    "\n",
    "We are going to use following equations:\n",
    "\n",
    "First since a lenght features of our vector are not equel to a lenght of our filter, we have to do simple linear (=dense) layer to expand feature vector into the feature filter (size of the embedding `feature_dimension`) input shape (`filter_dimension`)\n",
    "\n",
    "Convolution:\n",
    "$$\n",
    "\\mathbf{x}_i^{l+1}  = \\sum_{j=0}^{n_\\text{atoms}} \\mathbf{x}_j^l \\circ \\mathbf{R}^l(\\mathbf{r}_j - \\mathbf{r}_i)\n",
    "$$\n",
    "where R is the convolution filter generated via MLP from RBFs.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "What does this convolution actually do?\n",
    "\n",
    "This operation lets atoms exchange information with their neighbors, modulated by the distance-based filter.  \n",
    "The edge-dependent filter `R_ij` is constructed from the RBF features and scaled by the sender node embedding.\n",
    "\n",
    "The final output updates each node’s feature by aggregating messages from its neighbors, preserving rotational invariance.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "\n",
    "Why `scatter_add`?\n",
    "\n",
    "We compute messages for each edge (from `j` to `i`),  \n",
    "then sum them per receiving atom `i` to get the new node representation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvariantConvolution(nn.Module):\n",
    "    def __init__(self, \n",
    "                 feature_dimension, \n",
    "                 edge_dimension, \n",
    "                 filter_dimension, \n",
    "                 activation=F.silu):\n",
    "        super(InvariantConvolution, self).__init__()\n",
    "        self.node2filter = nn.Linear(feature_dimension, filter_dimension)\n",
    "        self.edge2filter = nn.Linear(edge_dimension, filter_dimension)\n",
    "        self.filter2out  = nn.Linear(filter_dimension, feature_dimension)\n",
    "        self.act = activation\n",
    "   \n",
    "    def forward(self,\n",
    "                x,\n",
    "                e_ij,\n",
    "                idx_i,\n",
    "                idx_j):\n",
    "        x = self.act(self.node2filter(x))\n",
    "        Rij = self.act(self.edge2filter(e_ij))\n",
    "        x_j = x[idx_j]\n",
    "        x_ij = x_j*Rij\n",
    "        x = scatter_add(x_ij, idx_i, dim=0)\n",
    "        x = self.filter2out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set a `filter_dimension` and call the newly coded Invariant Convolution, and take a look at the output's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 16])\n"
     ]
    }
   ],
   "source": [
    "filter_dimension = 32\n",
    "inv_conv = InvariantConvolution(feature_dimension,n_rbf,filter_dimension)\n",
    "out = inv_conv(node_embeddings,edge_embeddings,idx_i,idx_j)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full invariant message passing model `InvNet`**\n",
    "\n",
    "Now we can put everything together. \n",
    "\n",
    "Define a simple neural network that learns atomic representations via message passing based on rotationally invariant convolutions.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "\n",
    "The model:\n",
    "\n",
    "- embeds element types into feature vectors\n",
    "- expands interatomic distances via radial basis functions\n",
    "- updates node features through multiple invariant interaction blocks\n",
    "- outputs per-atom scalar predictions via a readout layer\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "What’s returned here?\n",
    "    \n",
    "The output is one scalar per atom. Later steps might aggregate these to get molecular properties.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple SO3-invariant representation \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dimension,\n",
    "        filter_dimension,\n",
    "        n_interactions, \n",
    "        radial_basis,\n",
    "        n_elements, \n",
    "        activation = F.silu\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_dimension: number of features to describe atomic environments.\n",
    "                This determines the size of each embedding vector; i.e. embeddings_dim.\n",
    "            n_interactions: number of interaction blocks.\n",
    "            lmax: maximum angular momentum of spherical harmonics basis\n",
    "            radial_basis: layer for expanding interatomic distances in a basis set\n",
    "            activation:\n",
    "        \"\"\"\n",
    "        super(InvNet, self).__init__()\n",
    "\n",
    "        self.feature_dimension = feature_dimension\n",
    "        self.filter_dimension = filter_dimension\n",
    "        self.n_interactions = n_interactions\n",
    "        self.radial_basis = radial_basis\n",
    "        self.edge_dimension = radial_basis.n_rbf\n",
    "        self.activation = activation\n",
    "        \n",
    "        # initialize embeddings\n",
    "        self.embedding = nn.Embedding(n_elements, feature_dimension)\n",
    "\n",
    "        # initialize linear mixing layers\n",
    "        self.linear = nn.Linear(feature_dimension, feature_dimension, bias=False)\n",
    "\n",
    "        # initialize invariant convolution\n",
    "        self.invconv  = InvariantConvolution(self.feature_dimension,\n",
    "                                             self.edge_dimension,\n",
    "                                             self.filter_dimension)\n",
    "        # initialize atomic readout\n",
    "        self.atomic_readout = nn.Linear(feature_dimension,1)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs: BatchedTorchAtoms):\n",
    "        \"\"\"\n",
    "        Compute atomic representations/embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict of torch.Tensor): torchAtoms with input tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: atom-wise representation.\n",
    "        \"\"\"\n",
    "        # get tensors from input \n",
    "        species_types = inputs.element_labels\n",
    "        r_ij = inputs.r_ij\n",
    "        d_ij = inputs.d_ij\n",
    "        dir_ij = inputs.dir_ij\n",
    "        idx_i = inputs.idx_i\n",
    "        idx_j = inputs.idx_j\n",
    "\n",
    "        # Radial embedding\n",
    "        e_ij = self.radial_basis(d_ij)\n",
    "\n",
    "        # Node embedding\n",
    "        x = self.embedding(species_types)\n",
    "\n",
    "        for t in range(self.n_interactions):\n",
    "            dx = self.invconv(x, e_ij, idx_i, idx_j)\n",
    "            x = x + dx\n",
    "\n",
    "        x = self.atomic_readout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model initialization**\n",
    "\n",
    "Set the hyperparameters and instantiate your invariant message passing model.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong> Hint </strong></summary>\n",
    "\n",
    "Keep in mind:\n",
    "- Only two element types (likely H and O) are present in the water cluster dataset (`n_elements`)\n",
    "- set dimensions, `rbf` and `cutoff`$\\ldots$\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 16\n",
    "filt_dim = 32\n",
    "n_rbf = 10\n",
    "cutoff = 3.0\n",
    "model = InvNet(\n",
    "    feat_dim, \n",
    "    filt_dim, \n",
    "    n_interactions=3,\n",
    "    radial_basis=SimpleRBF(n_rbf, cutoff),\n",
    "    n_elements=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load reference labels**\n",
    "\n",
    "*CHARGE!*\n",
    "\n",
    "Extract the (DFT) Hirshfeld charges as training targets for each atom.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong> Hint</strong></summary>\n",
    "\n",
    "- Read the `.xyz` and use some class defined in the very beginning regarding `atoms`-objects$\\ldots$\n",
    "- Fill a list with the targets\n",
    "- Ensures the target tensor has shape `[N, 1]` to match the model output and support broadcasting.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = read(\"waterAims.xyz@:10\",format=\"extxyz\")\n",
    "torch_mols = [TorchAtoms(mol) for mol in mols]\n",
    "batched_mols = BatchedTorchAtoms(torch_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 1])\n"
     ]
    }
   ],
   "source": [
    "ref_charges = []\n",
    "# print(mols[0].info\n",
    "for mol in mols:\n",
    "    ref_charges.extend(mol.arrays[\"dft_hirshfeld\"])\n",
    "ref_charges = torch.tensor(ref_charges,dtype=torch.float32).unsqueeze(-1) # unsqueeze for a proper shape as from torch-scatter\n",
    "print(ref_charges.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop**\n",
    "\n",
    "*No Pain, no gain!*\n",
    "\n",
    "Train the model to predict atomic charges via mean squared error loss.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "\n",
    "This simple example does not use dropout or batchnorm.\n",
    "Simply build a `for`-loop for the training.\n",
    "Define:\n",
    "- `n_epochs`\n",
    "- and optimizer\n",
    "- don't forget your model and loss\n",
    "- what do you have to call regarding the `grad` when in training ?\n",
    "- *optional but recommended: some tracking (e.g. every 10th epoch print epoch and loss)*\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     0 total loss: 0.147545\n",
      "#    10 total loss: 0.030945\n",
      "#    20 total loss: 0.016386\n",
      "#    30 total loss: 0.008683\n",
      "#    40 total loss: 0.005853\n",
      "#    50 total loss: 0.004378\n",
      "#    60 total loss: 0.003280\n",
      "#    70 total loss: 0.002561\n",
      "#    80 total loss: 0.002095\n",
      "#    90 total loss: 0.001797\n",
      "#   100 total loss: 0.001606\n",
      "#   110 total loss: 0.001470\n",
      "#   120 total loss: 0.001361\n",
      "#   130 total loss: 0.001264\n",
      "#   140 total loss: 0.001175\n",
      "#   150 total loss: 0.001092\n",
      "#   160 total loss: 0.001013\n",
      "#   170 total loss: 0.000939\n",
      "#   180 total loss: 0.000868\n",
      "#   190 total loss: 0.000801\n",
      "#   200 total loss: 0.000736\n",
      "#   210 total loss: 0.000674\n",
      "#   220 total loss: 0.000614\n",
      "#   230 total loss: 0.000558\n",
      "#   240 total loss: 0.000504\n",
      "#   250 total loss: 0.000452\n",
      "#   260 total loss: 0.000405\n",
      "#   270 total loss: 0.000361\n",
      "#   280 total loss: 0.000320\n",
      "#   290 total loss: 0.000284\n",
      "#   300 total loss: 0.000252\n",
      "#   310 total loss: 0.000224\n",
      "#   320 total loss: 0.000199\n",
      "#   330 total loss: 0.000178\n",
      "#   340 total loss: 0.000161\n",
      "#   350 total loss: 0.000145\n",
      "#   360 total loss: 0.000132\n",
      "#   370 total loss: 0.000120\n",
      "#   380 total loss: 0.000110\n",
      "#   390 total loss: 0.000102\n",
      "#   400 total loss: 0.000094\n",
      "#   410 total loss: 0.000087\n",
      "#   420 total loss: 0.000081\n",
      "#   430 total loss: 0.000075\n",
      "#   440 total loss: 0.000071\n",
      "#   450 total loss: 0.000066\n",
      "#   460 total loss: 0.000063\n",
      "#   470 total loss: 0.000059\n",
      "#   480 total loss: 0.000057\n",
      "#   490 total loss: 0.000054\n",
      "#   500 total loss: 0.000052\n",
      "#   510 total loss: 0.000050\n",
      "#   520 total loss: 0.000048\n",
      "#   530 total loss: 0.000046\n",
      "#   540 total loss: 0.000045\n",
      "#   550 total loss: 0.000044\n",
      "#   560 total loss: 0.000042\n",
      "#   570 total loss: 0.000041\n",
      "#   580 total loss: 0.000040\n",
      "#   590 total loss: 0.000039\n",
      "#   600 total loss: 0.000039\n",
      "#   610 total loss: 0.000038\n",
      "#   620 total loss: 0.000037\n",
      "#   630 total loss: 0.000036\n",
      "#   640 total loss: 0.000036\n",
      "#   650 total loss: 0.000035\n",
      "#   660 total loss: 0.000035\n",
      "#   670 total loss: 0.000034\n",
      "#   680 total loss: 0.000034\n",
      "#   690 total loss: 0.000033\n",
      "#   700 total loss: 0.000033\n",
      "#   710 total loss: 0.000032\n",
      "#   720 total loss: 0.000032\n",
      "#   730 total loss: 0.000032\n",
      "#   740 total loss: 0.000031\n",
      "#   750 total loss: 0.000031\n",
      "#   760 total loss: 0.000031\n",
      "#   770 total loss: 0.000030\n",
      "#   780 total loss: 0.000030\n",
      "#   790 total loss: 0.000030\n",
      "#   800 total loss: 0.000029\n",
      "#   810 total loss: 0.000029\n",
      "#   820 total loss: 0.000029\n",
      "#   830 total loss: 0.000029\n",
      "#   840 total loss: 0.000028\n",
      "#   850 total loss: 0.000028\n",
      "#   860 total loss: 0.000028\n",
      "#   870 total loss: 0.000028\n",
      "#   880 total loss: 0.000028\n",
      "#   890 total loss: 0.000027\n",
      "#   900 total loss: 0.000027\n",
      "#   910 total loss: 0.000027\n",
      "#   920 total loss: 0.000027\n",
      "#   930 total loss: 0.000027\n",
      "#   940 total loss: 0.000026\n",
      "#   950 total loss: 0.000026\n",
      "#   960 total loss: 0.000026\n",
      "#   970 total loss: 0.000026\n",
      "#   980 total loss: 0.000026\n",
      "#   990 total loss: 0.000025\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs):\n",
    "    #model.train()\n",
    "    q     = model(batched_mols)\n",
    "    loss  = F.mse_loss(q, ref_charges)\n",
    "    # if epoch%10==0:\n",
    "        # print(f\"# {epoch:5} charges: {q.T}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"# {epoch:5} total loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction vs. reference**\n",
    "\n",
    "Compare predicted atomic charges to DFT reference using a scatter plot.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong>Hint:</strong> What would perfect predictions look like?</summary>\n",
    "\n",
    "All points lie on the diagonal: predicted charge = reference charge.<br>\n",
    "*Optional:* add this diagonal as visual reference.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2b2c2ad850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = model(batched_mols)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ref_charges.detach().numpy(),q.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Larger Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rerun with larger model**\n",
    "\n",
    "Increase model capacity by using more features, interactions, and wider RBF coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 64\n",
    "filt_dim = 120\n",
    "n_rbf = 20\n",
    "cutoff = 6.0\n",
    "model = InvNet(\n",
    "    feat_dim, \n",
    "    filt_dim, \n",
    "    n_interactions=6,\n",
    "    radial_basis=SimpleRBF(n_rbf, cutoff),\n",
    "    n_elements=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create batches**\n",
    "\n",
    "Split dataset into batches of 10 molecules and collect reference charges per batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = read(\"waterAims.xyz@:50\",format=\"extxyz\")\n",
    "# torch_mols = [TorchAtoms(mol) for mol in mols]\n",
    "# batches = [BatchedTorchAtoms(torch_mols[x:x+5]) for x in range(len(torch_mols))]\n",
    "# batched_mols = BatchedTorchAtoms(torch_mols)\n",
    "ref_charges = []\n",
    "batches = []\n",
    "for id_some_mols in range(0,len(mols),10):\n",
    "    tmp_batch = []\n",
    "    tmp_charges = []\n",
    "    for mol in mols[id_some_mols:id_some_mols+10]:\n",
    "        tmp_charges.extend(mol.arrays[\"dft_hirshfeld\"])\n",
    "        tmp_batch.append(TorchAtoms(mol))\n",
    "    batches.append(BatchedTorchAtoms(tmp_batch))\n",
    "    tmp_charges = torch.tensor(tmp_charges,dtype=torch.float32).unsqueeze(-1) # unsqueeze for a proper shape as from torch-scatter\n",
    "    ref_charges.append(tmp_charges)\n",
    "# print(ref_charges.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7245, 0.9662, 0.9661, 2.8531, 1.7603, 2.8621, 1.5403, 2.6572, 0.9661,\n",
      "        2.2314])\n",
      "tensor([2.8691, 0.9537, 1.9271, 2.8689, 1.9145, 0.9726, 2.7467, 2.6324, 2.6279,\n",
      "        1.5457])\n",
      "tensor([1.8531, 2.9247, 0.9676, 2.8422, 0.9639, 2.7924, 1.9886, 2.3616, 2.6501,\n",
      "        2.8040])\n",
      "tensor([0.9641, 2.8095, 0.9679, 2.7794, 2.9792, 1.8242, 2.8868, 2.9883, 1.5345,\n",
      "        0.9641])\n",
      "tensor([1.7523, 0.9539, 0.9719, 2.7400, 2.7237, 2.5074, 1.5355, 0.9539, 1.5355,\n",
      "        0.9719])\n"
     ]
    }
   ],
   "source": [
    "for a in batches:\n",
    "    print(a.d_ij[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training over batches**\n",
    "\n",
    "Loop over batches to compute loss and update model parameters.\n",
    "<br><br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "\n",
    "Similar to before. Accumulate total loss to monitor progress across the entire dataset, not just one batch.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     0 total loss: 1.391708\n",
      "#    10 total loss: 0.004111\n",
      "#    20 total loss: 0.000817\n",
      "#    30 total loss: 0.000671\n",
      "#    40 total loss: 0.000585\n",
      "#    50 total loss: 0.000521\n",
      "#    60 total loss: 0.000470\n",
      "#    70 total loss: 0.000426\n",
      "#    80 total loss: 0.000388\n",
      "#    90 total loss: 0.000356\n",
      "#   100 total loss: 0.000328\n",
      "#   110 total loss: 0.000304\n",
      "#   120 total loss: 0.000284\n",
      "#   130 total loss: 0.000267\n",
      "#   140 total loss: 0.000252\n",
      "#   150 total loss: 0.000239\n",
      "#   160 total loss: 0.000228\n",
      "#   170 total loss: 0.000219\n",
      "#   180 total loss: 0.000211\n",
      "#   190 total loss: 0.000204\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0.0\n",
    "    for mol, ref_q in zip(batches, ref_charges):\n",
    "        optimizer.zero_grad()\n",
    "        q = model(mol)\n",
    "        loss = F.mse_loss(q, ref_q)\n",
    "        loss.backward()         # Accumulate gradients\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"# {epoch:5} total loss: {total_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ldots$ and visualize again via scatter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2b2c1dff10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = model(batches[2])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ref_charges[2].detach().numpy(),q.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You’ve just built and trained your **first rotationally invariant neural network** for atomistic systems.\n",
    "\n",
    "From embeddings to message passing and radial filters – this pipeline forms the core of many modern models in computational chemistry and materials science.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Where to go from here?</strong> (click)</summary>\n",
    "\n",
    "- Try training on larger datasets or predicting other atomic/molecular properties.  \n",
    "- Add angular information for directional interactions (e.g. using spherical harmonics).  \n",
    "- Implement multiple convolution blocks or skip connections.  \n",
    "- Compare performance with baseline methods.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivariant NN - SO3Net "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we start by defining an embedding for the elements present in our dataset.  \n",
    "For this, we can copy the idea from the invariant model.\n",
    "  \n",
    "Extract the number of distinct elements from the `BatchedTorchAtoms` object and define an embedding with `feature_dimension=16`.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "What is the input to `nn.Embedding`?\n",
    "    \n",
    "You need the number of distinct atomic types (`n_elements`) as first argument, and the embedding dimension (`feature_dimension`) as second.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8068,  0.6825,  0.8130,  ...,  1.3497, -1.0661,  0.9462],\n",
      "        [-0.6554, -0.6167, -0.3515,  ...,  0.9679,  1.6638, -1.5025],\n",
      "        [-0.6554, -0.6167, -0.3515,  ...,  0.9679,  1.6638, -1.5025],\n",
      "        ...,\n",
      "        [ 0.8068,  0.6825,  0.8130,  ...,  1.3497, -1.0661,  0.9462],\n",
      "        [-0.6554, -0.6167, -0.3515,  ...,  0.9679,  1.6638, -1.5025],\n",
      "        [-0.6554, -0.6167, -0.3515,  ...,  0.9679,  1.6638, -1.5025]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([240, 16])\n"
     ]
    }
   ],
   "source": [
    "n_elements = batched_mols.n_elements\n",
    "species_types = batched_mols.element_labels\n",
    "feature_dimension = 16\n",
    "element_embedding = nn.Embedding(n_elements, feature_dimension)\n",
    "node_embeddings = element_embedding(species_types)\n",
    "print(node_embeddings)\n",
    "print(node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Basis & Edge Embedding\n",
    "\n",
    "Additionally, we again need a radial basis to represent the edge features.  \n",
    "We will reuse the `SimpleRBF` class from the invariant model.\n",
    " \n",
    "Using `SimpleRBF`, define a radial basis with:\n",
    "- 10 radial functions (`n_rbf = 10`)\n",
    "- cutoff radius of `3.0 Å`\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Hint</strong></summary>\n",
    "What’s the input to `SimpleRBF`?\n",
    "    \n",
    "You need to specify `n_rbf` and `cutoff`. No need to change the `start` value.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a reminder cell, no need to reimplement this\n",
    "\n",
    "class SimpleRBF(nn.Module):\n",
    "    def __init__(self, n_rbf, cutoff, start=0.0):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, cutoff, n_rbf)\n",
    "        width  = torch.abs(offset[1] - offset[0])\n",
    "        self.n_rbf = n_rbf\n",
    "        self.register_buffer(\"offset\", offset)\n",
    "        self.register_buffer(\"widths\", torch.full_like(offset, width))\n",
    "\n",
    "    def forward(self, d_ij):\n",
    "        return torch.exp(-((d_ij.unsqueeze(-1) - self.offset) ** 2) / self.widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1558, 10])\n",
      "tensor([[2.1320e-10, 3.5522e-08, 3.0386e-06,  ..., 6.3189e-01, 9.9001e-01,\n",
      "         7.9637e-01],\n",
      "        [6.0783e-02, 3.0076e-01, 7.6406e-01,  ..., 3.6706e-03, 1.7079e-04,\n",
      "         4.0801e-06],\n",
      "        [6.0807e-02, 3.0084e-01, 7.6416e-01,  ..., 3.6685e-03, 1.7067e-04,\n",
      "         4.0766e-06],\n",
      "        ...,\n",
      "        [2.8709e-05, 8.6100e-04, 1.3258e-02,  ..., 5.2095e-01, 1.4692e-01,\n",
      "         2.1273e-02],\n",
      "        [2.4658e-12, 6.9155e-10, 9.9578e-08,  ..., 2.7984e-01, 7.3803e-01,\n",
      "         9.9931e-01],\n",
      "        [8.1910e-04, 1.2749e-02, 1.0189e-01,  ..., 1.5077e-01, 2.2068e-02,\n",
      "         1.6584e-03]])\n"
     ]
    }
   ],
   "source": [
    "n_rbf = 10\n",
    "cutoff = 3.0\n",
    "RBF = SimpleRBF(n_rbf,cutoff)\n",
    "edge_embeddings = RBF(d_ij)\n",
    "\n",
    "print(edge_embeddings.shape)\n",
    "print(edge_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivariant convolution (SO(3) tensor coupling)\n",
    "\n",
    "Now comes the critical part that separates **SO3Net** from simpler invariant models like **SchNet**:  \n",
    "the **equivariant convolution**. This operation couples edge and node features in a way that respects the transformation properties (irreducible representations, or *irreps*) under 3D rotations.\n",
    "\n",
    "In contrast to invariant convolutions, we must now ensure that **the character of each feature is preserved** throughout the network. This is what enables the model to remain **equivariant under SO(3) transformations**, i.e. to transform predictably under rotations.\n",
    "\n",
    "We encode the feature types via:\n",
    "\n",
    "`irrep_l = [\"x0e\",\"...\"]`\n",
    "\n",
    "These define the structure of the irreps for the different angular momentum orders `l`, alternating between even/odd parity (`e/o`).\n",
    "\n",
    "**Convolution workflow**\n",
    "\n",
    "This convolution works by projecting both node and edge features into a **shared latent space**\n",
    "and coupling them using spherical harmonics and a **tensor product** (via `e3nn.o3.FullyConnectedTensorProduct`).\n",
    "\n",
    "We are going to perform the following steps:\n",
    "\n",
    "1. **Edge MLP projection:**\n",
    "   Project the edge embeddings (i.e. RBF-expanded distances) through a fully connected layer with activation.\n",
    "   This transforms them into a suitable filter tensor `W_ij`.\n",
    "\n",
    "2. **Spherical harmonics computation:**\n",
    "   Use `e3nn.o3.spherical_harmonics` to encode the directional relation between atoms via `r_ij`.\n",
    "\n",
    "3. **Tensor product coupling:**\n",
    "   Perform the tensor product between node features `x_j`, the spherical harmonics, and the filter weights `W_ij`.\n",
    "   This step is **structure-aware** and **equivariant**.\n",
    "\n",
    "4. **Aggregation via scatter sum:**\n",
    "   Aggregate the messages sent to each atom `i` from its neighbors `j` using `scatter_add`.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "Why spherical harmonics?\n",
    "    \n",
    "Spherical harmonics serve as a rotational basis for directional interactions.\n",
    "By combining them with scalar edge features and node features via tensor product, we preserve equivariance.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    " Why `FullyConnectedTensorProduct`?\n",
    "    \n",
    "This module generalizes matrix multiplication to `SO(3)`-equivariant representations.\n",
    "It defines how two irreps (e.g. node and direction) can be coupled into an output irrep.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary><strong>Task</strong>\n",
    "\n",
    "Implement an equivariant convolution module with the following interface: *(click to expand)* </summary>\n",
    "\n",
    "- **Constructor inputs:**\n",
    "\n",
    "  * `lmax`: maximum angular momentum of spherical harmonics\n",
    "  * `feature_dimension`: dimension per irrep block\n",
    "  * `edge_dimension`: input dimension of edge features\n",
    "  * `activation`: nonlinearity (e.g. `F.silu`)\n",
    "\n",
    "- **Forward inputs:**\n",
    "\n",
    "  * `x`: node features (with irreps defined by `lmax` and `feature_dimension`)\n",
    "  * `e_ij`: edge features (from RBF)\n",
    "  * `r_ij`: relative position vectors\n",
    "  * `idx_i`, `idx_j`: indices of atom pairs for message passing\n",
    "\n",
    "- **Steps in `forward`:**\n",
    "\n",
    "  * Compute spherical harmonics `Y_lm(r_ij)` using `o3.spherical_harmonics`\n",
    "  * Use an MLP (`Linear + activation`) on `e_ij` to get filter weights `W_ij`\n",
    "  * Apply a tensor product `x_j ⊗ Y_lm ⊗ W_ij` to compute messages\n",
    "  * Aggregate messages for each target atom `i` via `scatter_add`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrep_l = [\"x0e\",\"x1o\",\"x2e\",\"x3o\",\"x4e\"] \n",
    "\n",
    "class EquivariantConvolution(nn.Module):\n",
    "    def __init__(self, \n",
    "                 lmax,\n",
    "                 feature_dimension, \n",
    "                 edge_dimension, \n",
    "                 activation=F.silu):\n",
    "        super(EquivariantConvolution, self).__init__()\n",
    "        self.lmax = lmax\n",
    "\n",
    "        # Prepare the irreducible representations\n",
    "        self.irreps_sh = o3.Irreps.spherical_harmonics(lmax=lmax)\n",
    "        irrep_string = f\"{feature_dimension}{irrep_l[0]}\"\n",
    "        for l in range(lmax):\n",
    "            irrep_string += f\" + {feature_dimension}{irrep_l[l+1]}\"\n",
    "        self.irreps_x  = o3.Irreps(irrep_string)\n",
    "        \n",
    "        # Define the tensor product and other neural network components\n",
    "        self.tp = o3.FullyConnectedTensorProduct(irreps_in1=self.irreps_x, \n",
    "                                                 irreps_in2=self.irreps_sh, \n",
    "                                                 irreps_out=self.irreps_x, \n",
    "                                                 shared_weights=False)\n",
    "\n",
    "        self.edge2filter = nn.Linear(edge_dimension, self.tp.weight_numel)\n",
    "        self.act = activation\n",
    "        \n",
    "    def forward(self,\n",
    "                x,\n",
    "                e_ij,\n",
    "                r_ij,\n",
    "                idx_i,\n",
    "                idx_j):\n",
    "\n",
    "        ylm = o3.spherical_harmonics(self.irreps_sh, r_ij, normalize=True, normalization='component')\n",
    "\n",
    "        Wij = self.act(self.edge2filter(e_ij))\n",
    "\n",
    "        x_j  = x[idx_j]\n",
    "        x_ij = self.tp(x_j,ylm,Wij)\n",
    "\n",
    "        x = scatter_add(x_ij, idx_i, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using your `EquivariantConvolution`-class, define a convolution with a `feature_dimension` of 16 and `lmax` of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "eq_conv = EquivariantConvolution(\n",
    "    lmax=1,\n",
    "    feature_dimension=feature_dimension,# As defined above\n",
    "    edge_dimension=RBF.n_rbf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first equivariant network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar-to-irrep expansion\n",
    "\n",
    "Before feeding scalar node embeddings into an `SO(3)`-equivariant network,  \n",
    "we need to lift them into the appropriate tensor shape for spherical harmonic coupling.\n",
    "\n",
    "Build a helper function that expands a `[N_atoms, N_features]` tensor into a padded form matching  \n",
    "the irreducible representation structure up to angular momentum `lmax`.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    " Why pad with zeros?\n",
    "    \n",
    "The initial node features are scalars (`l=0`). To match the full SO(3) structure,  \n",
    "we zero-pad the higher-`l` components before further equivariant processing.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_scalar_tensor(x: torch.Tensor, lmax: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Expand scalar tensor to spherical harmonics shape with angular momentum up to `lmax`\n",
    "\n",
    "    Args:\n",
    "        x: tensor of shape [N_atoms, N_features]\n",
    "        lmax: maximum angular momentum\n",
    "\n",
    "    Returns:\n",
    "        zero-padded tensor to shape [N_atoms, (lmax+1)^2*N_features]\n",
    "    \"\"\"\n",
    "    x = x.unsqueeze(1)\n",
    "    \n",
    "    y = torch.cat(\n",
    "        [\n",
    "            x,\n",
    "            torch.zeros(\n",
    "                (x.shape[0], int((lmax + 1) ** 2 - 1), x.shape[2]),\n",
    "                device=x.device,\n",
    "                dtype=x.dtype,\n",
    "            ),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    return torch.reshape(y,(x.shape[0],(lmax+1)**2*x.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple `SO(3)`-equivariant neural network\n",
    "\n",
    "This model implements a basic `SO(3)`-equivariant message passing network using irreducible representations.\n",
    "\n",
    "The architecture:\n",
    "\n",
    "- Embeds atoms as scalars (`l=0`) and expands them to match a full SO(3) irrep structure (via `expand_scalar_tensor`)\n",
    "- Represents directional edge information via spherical harmonics and RBFs\n",
    "- Applies several rounds of equivariant convolutions (with `l ≤ lmax`)\n",
    "- Predicts a vector-valued property (e.g. molecular dipole) using an equivariant linear readout (`l=1`)\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "    \n",
    " Why `1x1o` for the readout?\n",
    "\n",
    "Dipole moments are 3D vectors. In `SO(3)` terms, these transform like `l=1` irreps with odd parity (`1o`).\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEqNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple SO3-equivariant representation \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dimension,\n",
    "        lmax,\n",
    "        n_interactions, \n",
    "        radial_basis,\n",
    "        n_elements, \n",
    "        activation = F.silu\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_dimension: number of features to describe atomic environments.\n",
    "                This determines the size of each embedding vector; i.e. embeddings_dim.\n",
    "            n_interactions: number of interaction blocks.\n",
    "            lmax: maximum angular momentum of spherical harmonics basis\n",
    "            radial_basis: layer for expanding interatomic distances in a basis set\n",
    "            activation:\n",
    "        \"\"\"\n",
    "        super(SimpleEqNet, self).__init__()\n",
    "\n",
    "        self.feature_dimension = feature_dimension\n",
    "        self.lmax = lmax\n",
    "        self.hidden_irreps = o3.Irreps(f\"{self.feature_dimension}x0e+{self.feature_dimension}x1o\") # works only for lmax = 1\n",
    "        self.n_interactions = n_interactions\n",
    "        self.radial_basis = radial_basis\n",
    "        self.edge_dimension = radial_basis.n_rbf\n",
    "        self.activation = activation\n",
    "        \n",
    "        # initialize embeddings\n",
    "        self.embedding = nn.Embedding(n_elements, feature_dimension)\n",
    "\n",
    "        # initialize equivariant convolution\n",
    "        self.equconv  = EquivariantConvolution(self.lmax,\n",
    "                                               self.feature_dimension,\n",
    "                                               self.edge_dimension,\n",
    "                                               )\n",
    "        \n",
    "        self.dipole_out = o3.Irreps(\"1x1o\")\n",
    "        self.dipoles_read = o3.Linear(irreps_in=self.hidden_irreps, irreps_out=self.dipole_out)\n",
    "\n",
    "\n",
    "    def forward(self, inputs: BatchedTorchAtoms):\n",
    "        \"\"\"\n",
    "        Compute atomic representations/embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict of torch.Tensor): torchAtoms with input tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: atom-wise representation.\n",
    "        \"\"\"\n",
    "        # get tensors from input \n",
    "        species_types = inputs.element_labels\n",
    "        r_ij = inputs.r_ij\n",
    "        d_ij = inputs.d_ij\n",
    "        dir_ij = inputs.dir_ij\n",
    "        idx_i = inputs.idx_i\n",
    "        idx_j = inputs.idx_j\n",
    "\n",
    "        # Radial embedding\n",
    "        e_ij = self.radial_basis(d_ij)\n",
    "\n",
    "        # Node embedding\n",
    "        x = self.embedding(species_types)\n",
    "        x = expand_scalar_tensor(x,self.lmax)\n",
    "\n",
    "        # Message passing\n",
    "        for t in range(self.n_interactions):\n",
    "            dx = self.equconv(x, e_ij, r_ij, idx_i, idx_j)\n",
    "            x = x + dx\n",
    "        \n",
    "        # Read out\n",
    "        dipoles = self.dipoles_read(x)\n",
    "        total_dipole = scatter_sum( # stolen from mace\n",
    "            src=dipoles,\n",
    "            index=inputs.mol_id,\n",
    "            dim=0,\n",
    "            dim_size=inputs.n_mols,\n",
    "        )\n",
    "        return total_dipole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your first equivariant NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dipole prediction with equivariant GNN**\n",
    "\n",
    "We now train the equivariant network to predict the **total molecular dipole**  \n",
    "from atom-wise representations, aggregated via equivariant readout.\n",
    "\n",
    "Now, build the training loop by correctly passing the reference dipole into the loss function.  \n",
    "\n",
    "<details>\n",
    "<summary><strong> Hint</strong></summary>\n",
    "\n",
    "Use `loss = F.mse_loss(dip, reference_dipole)`, since we want to train on the dipoles.\n",
    "\n",
    "The current setup processes a single molecule as one batch.  \n",
    "For multiple systems, per-molecule dipoles would need to be computed and compared individually - cf. the batched invariant NN training above.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_elements = batched_mols.n_elements\n",
    "lmax = 1\n",
    "feature_dimension = 16\n",
    "gnn = SimpleEqNet(feature_dimension,lmax,3,RBF,n_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the body order: Tensor Product, Mixing and Gating\n",
    "\n",
    "To move from a simple equivariant message passing network to a **fully expressive SO(3)Net-like architecture**,  \n",
    "we need to increase the **body order** and model more complex local geometric interactions.\n",
    "\n",
    "This is achieved through the following additions:\n",
    "\n",
    "1. A **mixing layer** that prepares node features for interaction\n",
    "2. A **tensor product** that increases the body order (e.g. from 2-body to 3-body terms)\n",
    "3. A **gating mechanism** that enables non-linear interactions for higher-order irreps\n",
    "4. Additional **mixing layers** before and after gating\n",
    "\n",
    "<details>\n",
    "<summary><strong>Architecture overview</strong> (click to expand)</summary>\n",
    "\n",
    "Each interaction block now proceeds through:\n",
    "\n",
    "- **Equivariant convolution**: Couples neighbors via direction-aware message passing\n",
    "- **Linear mixing**: Prepares node features for interaction\n",
    "- **Tensor product**: Increases local body order (e.g. captures angular correlations)\n",
    "- **Gate**: Applies scalar-controlled nonlinearity to non-scalar features\n",
    "- **Residual update**: Adds processed message to current node state\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Hint</strong></summary>\n",
    "\n",
    "What is “body order”?\n",
    "\n",
    "The body order describes how many atoms interact simultaneously in a feature.  \n",
    "E.g., standard message passing is 2-body (central atom + neighbor),  \n",
    "while tensor product can model 3-body or higher interactions (center + 2 neighbors, angular structures).\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong></summary>\n",
    "    \n",
    "What does the gate do?\n",
    "\n",
    "Scalars are passed through a nonlinearity (e.g. sigmoid) and used to modulate the amplitudes  \n",
    "of higher-order (vector/tensor) components. This enables non-linear equivariant processing.\n",
    "\n",
    "</details>\n",
    "\n",
    "This network retains full SO(3)-equivariance and is expressive enough for vector- and tensor-valued predictions.  \n",
    "Here, the readout produces a dipole vector (`1×1o`) as the final molecular property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A more involved SO3-equivariant representation \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dimension,\n",
    "        lmax,\n",
    "        n_interactions, \n",
    "        radial_basis,\n",
    "        n_elements, \n",
    "        activation = F.silu\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_dimension: number of features to describe atomic environments.\n",
    "                This determines the size of each embedding vector; i.e. embeddings_dim.\n",
    "            n_interactions: number of interaction blocks.\n",
    "            lmax: maximum angular momentum of spherical harmonics basis\n",
    "            radial_basis: layer for expanding interatomic distances in a basis set\n",
    "            activation:\n",
    "        \"\"\"\n",
    "        super(EqNet, self).__init__()\n",
    "\n",
    "        self.feature_dimension = feature_dimension\n",
    "        self.lmax = lmax\n",
    "        self.hidden_irreps = o3.Irreps(f\"{self.feature_dimension}x0e+{self.feature_dimension}x1o\") # works only for lmax = 1\n",
    "        self.n_interactions = n_interactions\n",
    "        self.radial_basis = radial_basis\n",
    "        self.edge_dimension = radial_basis.n_rbf\n",
    "        self.activation = activation\n",
    "        \n",
    "        # initialize embeddings\n",
    "        self.embedding = nn.Embedding(n_elements, feature_dimension)\n",
    "\n",
    "        # initialize linear mixing layers\n",
    "        # self.linear = nn.Linear(feature_dimension, feature_dimension, bias=False)\n",
    "\n",
    "        # initialize equivariant convolution\n",
    "        self.equconv  = EquivariantConvolution(self.lmax,\n",
    "                                               self.feature_dimension,\n",
    "                                               self.edge_dimension,\n",
    "                                               )\n",
    "        \n",
    "        # initialize mixing before the tensor product\n",
    "        self.mixing_to_tp = o3.Linear(irreps_in=self.hidden_irreps,irreps_out=self.hidden_irreps)\n",
    "\n",
    "        # initialize the tensor product\n",
    "        self.tp = o3.FullyConnectedTensorProduct(irreps_in1=self.hidden_irreps, irreps_in2=self.hidden_irreps, irreps_out=self.hidden_irreps,internal_weights=False)\n",
    "        \n",
    "        # separate the scalar features from the non-scalar features based on Irrep.l\n",
    "        irreps_scalars = o3.Irreps(\n",
    "            [(mul, ir) for mul, ir in self.hidden_irreps if ir.l == 0]\n",
    "        )\n",
    "        irreps_gated = o3.Irreps(\n",
    "            [(mul, ir) for mul, ir in self.hidden_irreps if ir.l > 0]\n",
    "        )\n",
    "        \n",
    "        # define an additionally needed amount of scalar features\n",
    "        irreps_gates = o3.Irreps([mul, \"0e\"] for mul, _ in irreps_gated)\n",
    "\n",
    "        # initialize the gating\n",
    "        self.gating = Gate(\n",
    "            irreps_scalars=irreps_scalars,\n",
    "            act_scalars=[torch.sigmoid],\n",
    "            irreps_gates=irreps_gates,\n",
    "            act_gates=[torch.sigmoid],\n",
    "            irreps_gated=irreps_gated\n",
    "        )\n",
    "\n",
    "        # define the total amount of irreps for the nonlinearity \n",
    "        self.irreps_nonlin = self.gating.irreps_in.simplify()\n",
    "\n",
    "        # initialize mixing layers before and after the gating\n",
    "        self.mixing_to_gate = o3.Linear(irreps_in=self.hidden_irreps,irreps_out=self.irreps_nonlin)\n",
    "        self.mixing_to_read = o3.Linear(irreps_in=self.hidden_irreps,irreps_out=self.hidden_irreps)\n",
    "\n",
    "        # initialize the readout\n",
    "        self.dipole_out = o3.Irreps(\"1x1o\")\n",
    "        self.dipoles_read = o3.Linear(irreps_in=self.hidden_irreps, irreps_out=self.dipole_out)\n",
    "\n",
    "\n",
    "    def forward(self, inputs: BatchedTorchAtoms):\n",
    "        \"\"\"\n",
    "        Compute atomic representations/embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict of torch.Tensor): torchAtoms with input tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: atom-wise representation.\n",
    "        \"\"\"\n",
    "        # get tensors from input \n",
    "        species_types = inputs.element_labels\n",
    "        r_ij = inputs.r_ij\n",
    "        d_ij = inputs.d_ij\n",
    "        dir_ij = inputs.dir_ij\n",
    "        idx_i = inputs.idx_i\n",
    "        idx_j = inputs.idx_j\n",
    "\n",
    "        # Radial embedding\n",
    "        e_ij = self.radial_basis(d_ij)\n",
    "\n",
    "        # Node embedding\n",
    "        x = self.embedding(species_types)\n",
    "        x = expand_scalar_tensor(x,self.lmax)\n",
    "\n",
    "        for t in range(self.n_interactions):\n",
    "            # Apply convolution\n",
    "            dx = self.equconv(x, e_ij, r_ij, idx_i, idx_j)\n",
    "            # Prepare the features for tensor product\n",
    "            ddx = self.mixing_to_tp(dx)\n",
    "            # Apply the tensor product\n",
    "            dx = dx + self.tp(dx, ddx,torch.ones(self.tp.weight_numel))\n",
    "            # Prepare the features for the gating\n",
    "            dx = self.mixing_to_gate(dx)\n",
    "            # Apply the gating\n",
    "            dx = self.gating(dx)\n",
    "            # Recover original dimension\n",
    "            dx = self.mixing_to_read(dx)\n",
    "            # Update node representation\n",
    "            x = x + dx\n",
    "        dipoles = self.dipoles_read(x)\n",
    "        # print(\"dipoles\",dipoles.shape)\n",
    "        total_dipole = scatter_sum( # stolen from mace\n",
    "            src=dipoles,\n",
    "            index=inputs.mol_id,\n",
    "            dim=0,\n",
    "            dim_size=inputs.n_mols,\n",
    "        )\n",
    "        return total_dipole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your fancy equivariant NN\n",
    "\n",
    "We now train the full SO(3)-equivariant network to predict the molecular **dipole vector**  \n",
    "based on the atom-wise learned features and directional message passing.\n",
    "\n",
    "Your job: Provide a complete training loop once more.\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Hint</strong></summary>\n",
    "    \n",
    "    You'll have to \n",
    "- get `n_elements`\n",
    "- set `lmax` and `feature_dimension`\n",
    "- instantiate the an `EqNet` object\n",
    "- read molecule data and use `TorchAtoms` resp. `BatchedTorchAtoms`\n",
    "- make sure you have the training information (`ref_dipole`) as a correctly shaped `torch.tensor`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/home/mvondrak/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_elements = batched_mols.n_elements\n",
    "lmax = 1\n",
    "feature_dimension = 16\n",
    "# gnn = SimpleEqNet(feature_dimension,lmax,3,RBF,n_elements)\n",
    "gnn = EqNet(feature_dimension,lmax,3,RBF,n_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78252/1126341311.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  ref_dipole = torch.tensor(ref_dipole,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "mols = read(\"waterAims.xyz@:10\",format=\"extxyz\")\n",
    "torch_mols = [TorchAtoms(mol) for mol in mols]\n",
    "batched_mols = BatchedTorchAtoms(torch_mols)\n",
    "\n",
    "ref_dipole = []\n",
    "# print(mols[0].info)\n",
    "for mol in mols:\n",
    "    ref_dipole.append(mol.info[\"dft_dipole\"])\n",
    "ref_dipole = torch.tensor(ref_dipole,dtype=torch.float32)\n",
    "print(ref_dipole.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after setting up everything, get the optimizer running in a training `for`-loop.\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Hint</strong></summary>\n",
    "    Basically the same as for the invariant network.\n",
    "    \n",
    "    Call the `forward`-method of your `EqNet`-object, calculate loss and don't forget to handle the gradient correctly!\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(gnn.parameters(), lr=1e-3)\n",
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    #gnn.train()\n",
    "    dip     = gnn(batched_mols)\n",
    "    # print(\"d\",dip.shape)\n",
    "    loss  = F.mse_loss(dip, ref_dipole)\n",
    "    # print(q.,reference_charges.shape)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally again, plot as a scatter plot once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2b3029ad00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ref_dipole.detach().numpy(),dip.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation equivariance test\n",
    "\n",
    "To verify that our network is truly `SO(3)`-equivariant, we compare its output on a molecule before and after a rigid rotation.\n",
    "\n",
    "Define a `rotation` function using `numpy.ndarray`'s.\n",
    "\n",
    "<details>\n",
    "<summary><strong>Hint</strong> What should hold if the network is equivariant?</summary>\n",
    "\n",
    "The predicted dipole after rotation should match the **rotated version** of the original prediction.\n",
    "    \n",
    "Steps:\n",
    "\n",
    "- Select a molecule (`i_mol`)\n",
    "- Predict dipole from original structure\n",
    "- Rotate the molecule around a chosen axis\n",
    "- Predict dipole again and compare with the rotated reference dipole\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "Afterwards, take a molecule and use your `EqNet`-object. Test before and after rotation - what should happen? And what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rotate_vector(v, axis, angle_rad):\n",
    "    axis = axis / np.linalg.norm(axis)  # normalize rotation axis\n",
    "    cos_theta = np.cos(angle_rad)\n",
    "    sin_theta = np.sin(angle_rad)\n",
    "    one_minus_cos = 1 - cos_theta\n",
    "    x, y, z = axis\n",
    "\n",
    "    # Rodrigues' rotation matrix\n",
    "    R = np.array([\n",
    "        [cos_theta + x*x*one_minus_cos,      x*y*one_minus_cos - z*sin_theta, x*z*one_minus_cos + y*sin_theta],\n",
    "        [y*x*one_minus_cos + z*sin_theta,    cos_theta + y*y*one_minus_cos,   y*z*one_minus_cos - x*sin_theta],\n",
    "        [z*x*one_minus_cos - y*sin_theta,    z*y*one_minus_cos + x*sin_theta, cos_theta + z*z*one_minus_cos  ]\n",
    "    ])\n",
    "\n",
    "    return R @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2460, -0.0517, -0.0959])\n",
      "[[0.22734719514846802, -0.08436277508735657, -0.07286977767944336]]\n",
      "[ 0.15782755 -0.05170073 -0.21165925]\n",
      "[[0.15418612957000732, -0.08436238765716553, -0.1822723150253296]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "i_mol = 9\n",
    "\n",
    "mol_orig = deepcopy(mols[i_mol])\n",
    "pred_orig_vector = gnn(BatchedTorchAtoms([TorchAtoms(mol_orig)])).tolist()\n",
    "rot_vec = rotate_vector(np.array(ref_dipole[i_mol,:]),(0,1,0),np.radians(32))\n",
    "mol_rots = deepcopy(mols[i_mol])\n",
    "mol_rots.rotate(32,(0,1,0))\n",
    "pred_rot_vector = gnn(BatchedTorchAtoms([TorchAtoms(mol_rots)])).tolist()\n",
    "\n",
    "print(ref_dipole[i_mol,:])\n",
    "print(pred_orig_vector)\n",
    "\n",
    "print(rot_vec)\n",
    "print(pred_rot_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations – you just trained your first fully SO(3)-equivariant neural network!\n",
    "\n",
    "You've now built a message-passing model that respects 3D geometry **by design**:  \n",
    "From scalar embeddings to equivariant convolutions, tensor products and gating –  \n",
    "this architecture forms the basis for state-of-the-art models in molecular and materials machine learning.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What’s next?</strong> (click me)</summary>\n",
    "\n",
    "- Predict forces, multipoles or energies using the same architecture  \n",
    "- Explore higher `lmax` values or more interaction layers  \n",
    "- Train on diverse molecular datasets (QM9, MD17, SPICE, ...)  \n",
    "- Benchmark against SchNet, DimeNet, or GemNet\n",
    "\n",
    "</details>\n",
    "\n",
    "_Equivariance is not a trick – it's a symmetry principle. And you’ve just made it learnable._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmonizing-flows-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
